{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "from pathlib import Path\n",
    "from typing import Sequence\n",
    "\n",
    "import matplotlib.axes._axes as axes\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.figure import Figure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(r\"C:\\Users\\balco\\Downloads\\phd_data\")\n",
    "# DAY_INDEX = range(81)\n",
    "# DAY_INDEX_MEAN = range(81)\n",
    "# DAY_INDEX = [20, 21, 22, 23, 24, 25, 26, 30] # performance by day\n",
    "DAY_INDEX = [20, 21, 22, 23,  51, 52, 53, 54] # performance by day\n",
    "DAY_INDEX_MEAN = [20, 21, 22, 23,  51, 52, 53, 54] # performance by day\n",
    "# DAY_INDEX_MEAN = range(81) # performance by day\n",
    "FOLDER_INDEX = [1]\n",
    "# DAY_ALONE_INDEX = [15]\n",
    "\n",
    "CB91_Blue = \"#2CBDFE\"\n",
    "CB91_Green = \"#47DBCD\"\n",
    "CB91_Pink = \"#F3A0F2\"\n",
    "CB91_Purple = \"#9D2EC5\"\n",
    "CB91_Violet = \"#661D98\"\n",
    "CB91_Amber = \"#F5B14C\"\n",
    "\n",
    "color_list = [\n",
    "    CB91_Blue,\n",
    "    CB91_Amber,\n",
    "    CB91_Green,\n",
    "    CB91_Violet,\n",
    "    CB91_Pink,\n",
    "    CB91_Purple,\n",
    "]\n",
    "\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(color=color_list)\n",
    "\n",
    "plt.rc(\"text\", usetex=True)\n",
    "plt.rc(\"font\", family=\"serif\")\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'es-MX')\n",
    "LOCATOR = mdates.AutoDateLocator(minticks=3, maxticks=5)\n",
    "FORMATTER = mdates.ConciseDateFormatter(LOCATOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_across_dataframes(dfs: Sequence[pd.DataFrame]) -> pd.DataFrame:\n",
    "    return pd.concat(dfs).groupby(level=0).mean()\n",
    "\n",
    "\n",
    "def read_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df.set_index(\"Date\", drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_dirs(name: str):\n",
    "    \"\"\"Get all directories which contain the specified word in their name\"\"\"\n",
    "    return PATH.glob(f\"*{name}*\")\n",
    "\n",
    "\n",
    "def get_file_from_dir(dir_: Path, index: int):\n",
    "    \"\"\"Get the csv at the specified position\"\"\"\n",
    "    return list(dir_.glob(\"*.csv\"))[index]\n",
    "\n",
    "\n",
    "def get_files(name: str, index: int):\n",
    "    \"\"\"\n",
    "    Get the csv files at the specified position for all the directories which contain the word `name`\n",
    "    \"\"\"\n",
    "    return (get_file_from_dir(d, index) for d in get_dirs(name))\n",
    "\n",
    "\n",
    "def combine_df(\n",
    "    dfs: Sequence[pd.DataFrame], names: Sequence[str], feature: str = \"Power\", feat_opt: str = \"Optimum Power\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combine multiple dataframes into a single one\n",
    "    \"\"\"\n",
    "\n",
    "    combined_df = {}\n",
    "\n",
    "    if feat_opt:\n",
    "        combined_df[names[-1]] = dfs[0][feat_opt]\n",
    "\n",
    "    for df, name in zip(dfs, names):\n",
    "        combined_df[name] = df[feature]\n",
    "\n",
    "    return pd.DataFrame(combined_df)\n",
    "\n",
    "\n",
    "def plot_combined(df: pd.DataFrame, ylabel: str = \"\", multiplier: int = 1, locator=None, formatter=None, effs=None) -> Figure:\n",
    "    locator = locator or LOCATOR\n",
    "    formatter = formatter or FORMATTER\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax: axes.Axes = fig.add_subplot(111)\n",
    "\n",
    "    effs = effs or compute_eff(df)\n",
    "\n",
    "    for column, eff in zip(df.columns, effs):\n",
    "        if 'Óptimo' in column:\n",
    "            continue\n",
    "        else:\n",
    "            label = f'{column} ({eff:.1f}\\%)'\n",
    "        ax.plot(df.index, df[column] * multiplier, label=label)\n",
    "\n",
    "    if 'Óptimo' in df.columns:\n",
    "        ax.plot(df.index, df['Óptimo'] * multiplier, 'k--', label='Óptimo')\n",
    "\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def compute_eff(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    sum_ = df.sum()\n",
    "    max_ = sum_[0]\n",
    "\n",
    "    effs = [s * 100 / max_ for s in sum_]\n",
    "\n",
    "    return effs\n",
    "\n",
    "\n",
    "def add_day_offset(df: pd.DataFrame, days: int) -> pd.DataFrame:\n",
    "    df.index = df.index + pd.DateOffset(days=days)\n",
    "    return df\n",
    "\n",
    "def subtract_day_offset(df: pd.DataFrame, days: int) -> pd.DataFrame:\n",
    "    df.index = df.index - pd.DateOffset(days=days)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_csv(path: Path) -> pd.DataFrame:\n",
    "#     df = pd.read_csv(path)\n",
    "#     df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "#     df.set_index(\"Date\", drop=True, inplace=True)\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def plot(df: pd.DataFrame):\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111)\n",
    "\n",
    "#     for col in df.columns:\n",
    "#         if \"Amb\" in col:\n",
    "#             continue  # Skip ambient temperatures\n",
    "#         ax.plot(df.index, df[col], label=LEGEND[col])\n",
    "#         ax.xaxis.set_major_locator(locator)\n",
    "#         ax.xaxis.set_major_formatter(formatter)\n",
    "#         ax.set_ylabel(\"Irradiancia solar $\\mathrm{(W/m^2)}$\")\n",
    "#         ax.legend(loc=\"upper left\")\n",
    "\n",
    "#     fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "\n",
    "#     return fig\n",
    "\n",
    "# def add_year_offset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     df.index = df.index + pd.DateOffset(years=1)\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def split_df_by_day(df: pd.DataFrame) -> Sequence[pd.DataFrame]:\n",
    "#     return [group[1] for group in df.groupby(df.index.date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_plot_train_day():\n",
    "    for i, day in enumerate(DAY_INDEX):\n",
    "        for j, folder in enumerate(FOLDER_INDEX):\n",
    "            po_train_files = [list(get_files(\"po_train\", day + 10))[0]]\n",
    "            ddpg_train_files = [list(get_files(\"ddpg_train\", day + 10))[folder]]\n",
    "            td3_train_files = [list(get_files(\"td3_train\", day + 10))[folder]]\n",
    "            td4_train_files = [list(get_files(\"td3exp_train\", day))[folder]]\n",
    "\n",
    "            assert len(po_train_files) == 1\n",
    "            assert len(ddpg_train_files) == 1\n",
    "            assert len(td3_train_files) == 1\n",
    "            assert len(td4_train_files) == 1\n",
    "\n",
    "            po_mean = mean_across_dataframes(read_csv(f) for f in po_train_files)\n",
    "            ddpg_mean = mean_across_dataframes((read_csv(f) for f in ddpg_train_files))\n",
    "            td3_mean = mean_across_dataframes((read_csv(f) for f in td3_train_files))\n",
    "            td4_mean = mean_across_dataframes((read_csv(f) for f in td4_train_files))\n",
    "\n",
    "            po_mean = add_day_offset(po_mean, days=-10)\n",
    "            ddpg_mean = add_day_offset(ddpg_mean, days=-10)\n",
    "            td3_mean = add_day_offset(td3_mean, days=-10)\n",
    "\n",
    "            # ddpg_mean['Efficiency'] = ddpg_mean['Efficiency'] - 0.01\n",
    "            # td4_mean['Efficiency'] = td4_mean['Efficiency'] + 0.015\n",
    "\n",
    "            po_eff = po_mean['Efficiency'].mean() * 100\n",
    "            ddpg_eff = ddpg_mean['Efficiency'].mean() * 100\n",
    "            td3_eff = td3_mean['Efficiency'].mean() * 100\n",
    "            td4_eff = td4_mean['Efficiency'].mean() * 100\n",
    "            effs = [0, po_eff, ddpg_eff, td3_eff, td4_eff]\n",
    "\n",
    "            df = combine_df(\n",
    "                [po_mean, ddpg_mean, td3_mean, td4_mean],\n",
    "                [\"P\\&O\",\"DDPG\", \"TD3\", \"TD4\", 'Óptimo'],\n",
    "                feature=\"Duty Cycle\", feat_opt='Optimum Duty Cycle'\n",
    "            )\n",
    "\n",
    "            p = plot_combined(df, ylabel=\"Ciclo de trabajo\", effs=effs)\n",
    "\n",
    "            p.savefig(f\"output\\\\fig_19_mppt_comparison_train_duty_cycle_day_{j:04}_{i:02}.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "            plt.close(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_train_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_plot_train_mean():\n",
    "    for i, day in enumerate(DAY_INDEX_MEAN):\n",
    "        po_train_files = [list(get_files(\"po_train\", day + 10))[0]]\n",
    "        ddpg_train_files = list(get_files(\"ddpg_train\", day + 10))\n",
    "        td3_train_files = list(get_files(\"td3_train\", day + 10))\n",
    "        td4_train_files = list(get_files(\"td3exp_train\", day))\n",
    "\n",
    "        assert len(po_train_files) == 1\n",
    "        assert len(ddpg_train_files) == 110\n",
    "        assert len(td3_train_files) == 110\n",
    "        assert len(td4_train_files) == 110\n",
    "\n",
    "        po_mean = mean_across_dataframes(read_csv(f) for f in po_train_files)\n",
    "        ddpg_mean = mean_across_dataframes((read_csv(f) for f in ddpg_train_files))\n",
    "        td3_mean = mean_across_dataframes((read_csv(f) for f in td3_train_files))\n",
    "        td4_mean = mean_across_dataframes((read_csv(f) for f in td4_train_files))\n",
    "\n",
    "        po_mean = add_day_offset(po_mean, days=-10)\n",
    "        ddpg_mean = add_day_offset(ddpg_mean, days=-10)\n",
    "        td3_mean = add_day_offset(td3_mean, days=-10)\n",
    "\n",
    "        po_eff = po_mean['Efficiency'].mean() * 100\n",
    "        ddpg_eff = ddpg_mean['Efficiency'].mean() * 100\n",
    "        td3_eff = td3_mean['Efficiency'].mean() * 100\n",
    "        td4_eff = td4_mean['Efficiency'].mean() * 100\n",
    "        effs = [0, po_eff, ddpg_eff, td3_eff, td4_eff]\n",
    "\n",
    "        df = combine_df(\n",
    "            [po_mean, ddpg_mean, td3_mean, td4_mean],\n",
    "            [\"P\\&O\",\"DDPG\", \"TD3\", \"TD4\", 'Óptimo'],\n",
    "            feature=\"Duty Cycle\", feat_opt='Optimum Duty Cycle'\n",
    "        )\n",
    "\n",
    "        p = plot_combined(df, ylabel=\"Ciclo de trabajo\", effs=effs)\n",
    "\n",
    "        p.savefig(f\"output\\\\fig_19_mppt_comparison_train_duty_cycle_mean_{i:02}.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "        plt.close(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_train_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('rl38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2d58166cc104020804edeacd7427d77b20cfad18516c79d640fb360ccf2c09a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
