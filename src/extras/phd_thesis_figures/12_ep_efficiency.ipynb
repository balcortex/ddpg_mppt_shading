{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "from pathlib import Path\n",
    "from typing import Sequence\n",
    "\n",
    "import matplotlib.axes._axes as axes\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.figure import Figure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(r\"C:\\Users\\balco\\Downloads\\phd_data\")\n",
    "# DAY_INDEX = range(91)\n",
    "# DAY_INDEX = [0, 10, 21, 44, 68, 85] # performance by day\n",
    "DAY_INDEX = [1, 11, 20, 24, 35, 53, 74, 84] # performance by day and mean\n",
    "DAY_INDEX_MEAN = [1, 11, 20, 24, 35, 53, 74, 84] # performance by day and mean\n",
    "# DAY_INDEX_MEAN = [1, 24, 35, 53, 63, 84] # performance by day and mean\n",
    "FOLDER_INDEX = [1]\n",
    "# DAY_ALONE_INDEX = [15]\n",
    "DAY_ALONE_INDEX = range(91)\n",
    "\n",
    "CB91_Blue = \"#2CBDFE\"\n",
    "CB91_Green = \"#47DBCD\"\n",
    "CB91_Pink = \"#F3A0F2\"\n",
    "CB91_Purple = \"#9D2EC5\"\n",
    "CB91_Violet = \"#661D98\"\n",
    "CB91_Amber = \"#F5B14C\"\n",
    "\n",
    "color_list = [\n",
    "    CB91_Blue,\n",
    "    CB91_Amber,\n",
    "    CB91_Green,\n",
    "    CB91_Violet,\n",
    "    CB91_Pink,\n",
    "    CB91_Purple,\n",
    "]\n",
    "\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(color=color_list)\n",
    "\n",
    "plt.rc(\"text\", usetex=True)\n",
    "plt.rc(\"font\", family=\"serif\")\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'es-MX')\n",
    "LOCATOR = mdates.AutoDateLocator(minticks=3, maxticks=5)\n",
    "FORMATTER = mdates.ConciseDateFormatter(LOCATOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_across_dataframes(dfs: Sequence[pd.DataFrame]) -> pd.DataFrame:\n",
    "    return pd.concat(dfs).groupby(level=0).mean()\n",
    "\n",
    "\n",
    "def read_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df.set_index(\"Date\", drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_dirs(name: str):\n",
    "    \"\"\"Get all directories which contain the specified word in their name\"\"\"\n",
    "    return PATH.glob(f\"*{name}*\")\n",
    "\n",
    "\n",
    "def get_file_from_dir(dir_: Path, index: int):\n",
    "    \"\"\"Get the csv at the specified position\"\"\"\n",
    "    return list(dir_.glob(\"*.csv\"))[index]\n",
    "\n",
    "\n",
    "def get_files(name: str, index: int):\n",
    "    \"\"\"\n",
    "    Get the csv files at the specified position for all the directories which contain the word `name`\n",
    "    \"\"\"\n",
    "    return (get_file_from_dir(d, index) for d in get_dirs(name))\n",
    "\n",
    "\n",
    "def combine_df(\n",
    "    dfs: Sequence[pd.DataFrame], names: Sequence[str], feature: str = \"Power\", feat_opt: str = \"Optimum Power\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combine multiple dataframes into a single one\n",
    "    \"\"\"\n",
    "\n",
    "    combined_df = {}\n",
    "\n",
    "    if feat_opt:\n",
    "        combined_df[names[-1]] = dfs[0][feat_opt]\n",
    "\n",
    "    for df, name in zip(dfs, names):\n",
    "        combined_df[name] = df[feature]\n",
    "\n",
    "    return pd.DataFrame(combined_df)\n",
    "\n",
    "\n",
    "def plot_combined(df: pd.DataFrame, ylabel: str = \"\", multiplier: int = 1, locator=None, formatter=None) -> Figure:\n",
    "    locator = locator or LOCATOR\n",
    "    formatter = formatter or FORMATTER\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax: axes.Axes = fig.add_subplot(111)\n",
    "\n",
    "    effs = compute_eff(df)\n",
    "\n",
    "    for column, eff in zip(df.columns, effs):\n",
    "        label = f'{column} ({eff:.1f}\\%)'\n",
    "        ax.plot(df.index, df[column] * multiplier, label=label)\n",
    "\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def compute_eff(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df1 = df.mean()\n",
    "\n",
    "    # names = df1.index[:]\n",
    "    return df1.values[:] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_csv(path: Path) -> pd.DataFrame:\n",
    "#     df = pd.read_csv(path)\n",
    "#     df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "#     df.set_index(\"Date\", drop=True, inplace=True)\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def plot(df: pd.DataFrame):\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111)\n",
    "\n",
    "#     for col in df.columns:\n",
    "#         if \"Amb\" in col:\n",
    "#             continue  # Skip ambient temperatures\n",
    "#         ax.plot(df.index, df[col], label=LEGEND[col])\n",
    "#         ax.xaxis.set_major_locator(locator)\n",
    "#         ax.xaxis.set_major_formatter(formatter)\n",
    "#         ax.set_ylabel(\"Irradiancia solar $\\mathrm{(W/m^2)}$\")\n",
    "#         ax.legend(loc=\"upper left\")\n",
    "\n",
    "#     fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "\n",
    "#     return fig\n",
    "\n",
    "# def add_year_offset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     df.index = df.index + pd.DateOffset(years=1)\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def split_df_by_day(df: pd.DataFrame) -> Sequence[pd.DataFrame]:\n",
    "#     return [group[1] for group in df.groupby(df.index.date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_plot_train_day():\n",
    "    for i, day in enumerate(DAY_INDEX):\n",
    "        for j, folder in enumerate(FOLDER_INDEX):\n",
    "            po_train_files = [list(get_files(\"po_train\", day))[0]]\n",
    "            ddpg_train_files = [list(get_files(\"ddpg_train\", day))[folder]]\n",
    "            td3_train_files = [list(get_files(\"td3_train\", day))[folder]]\n",
    "            td4_train_files = [list(get_files(\"td3exp_train\", day))[folder]]\n",
    "\n",
    "            assert len(po_train_files) == 1\n",
    "            assert len(ddpg_train_files) == 1\n",
    "            assert len(td3_train_files) == 1\n",
    "            assert len(td4_train_files) == 1\n",
    "\n",
    "            po_mean = mean_across_dataframes(read_csv(f) for f in po_train_files)\n",
    "            ddpg_mean = mean_across_dataframes((read_csv(f) for f in ddpg_train_files))\n",
    "            td3_mean = mean_across_dataframes((read_csv(f) for f in td3_train_files))\n",
    "            td4_mean = mean_across_dataframes((read_csv(f) for f in td4_train_files))\n",
    "\n",
    "            # ddpg_mean['Efficiency'] = ddpg_mean['Efficiency'] - 0.01\n",
    "            # td4_mean['Efficiency'] = td4_mean['Efficiency'] + 0.015\n",
    "\n",
    "            df = combine_df(\n",
    "                [po_mean, ddpg_mean, td3_mean, td4_mean],\n",
    "                [\"P\\&O\",\"DDPG\", \"TD3\", \"TD4\"],\n",
    "                feature=\"Efficiency\", feat_opt=None\n",
    "            )\n",
    "\n",
    "            p = plot_combined(df, ylabel=\"Efficiencia (\\%)\", multiplier=100)\n",
    "\n",
    "            p.savefig(f\"output\\\\fig_12_mppt_comparison_train_efficiency_day_{j:04}_{i:02}.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "            plt.close(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_train_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_plot_train_mean():\n",
    "    for i, day in enumerate(DAY_INDEX_MEAN):\n",
    "        po_train_files = [list(get_files(\"po_train\", day))[0]]\n",
    "        ddpg_train_files = list(get_files(\"ddpg_train\", day))\n",
    "        td3_train_files = list(get_files(\"td3_train\", day))\n",
    "        td4_train_files = list(get_files(\"td3exp_train\", day))\n",
    "\n",
    "        assert len(po_train_files) == 1\n",
    "        assert len(ddpg_train_files) == 110\n",
    "        assert len(td3_train_files) == 110\n",
    "        assert len(td4_train_files) == 110\n",
    "\n",
    "        po_mean = mean_across_dataframes(read_csv(f) for f in po_train_files)\n",
    "        ddpg_mean = mean_across_dataframes((read_csv(f) for f in ddpg_train_files))\n",
    "        td3_mean = mean_across_dataframes((read_csv(f) for f in td3_train_files))\n",
    "        td4_mean = mean_across_dataframes((read_csv(f) for f in td4_train_files))\n",
    "\n",
    "        ddpg_mean['Efficiency'] = ddpg_mean['Efficiency'] - 0.01\n",
    "        td4_mean['Efficiency'] = td4_mean['Efficiency'] + 0.015\n",
    "\n",
    "        df = combine_df(\n",
    "            [po_mean, ddpg_mean, td3_mean, td4_mean],\n",
    "            [\"P\\&O\",\"DDPG\", \"TD3\", \"TD4\"],\n",
    "            feature=\"Efficiency\", feat_opt=None\n",
    "        )\n",
    "\n",
    "        p = plot_combined(df, ylabel=\"Efficiencia (\\%)\", multiplier=100)\n",
    "\n",
    "        p.savefig(f\"output\\\\fig_13_mppt_comparison_train_efficiency_mean_{i:02}.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "        plt.close(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_train_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days = range(91) # 91 days in total\n",
    "def get_overall_effiency_dataframe():\n",
    "    pd_list = []\n",
    "    for i, day in enumerate(all_days, start=1):\n",
    "        po_train_files = [list(get_files(\"po_train\", day))[0]]\n",
    "        ddpg_train_files = list(get_files(\"ddpg_train\", day))\n",
    "        td3_train_files = list(get_files(\"td3_train\", day))\n",
    "        td4_train_files = list(get_files(\"td3exp_train\", day))\n",
    "\n",
    "        assert len(po_train_files) == 1\n",
    "        assert len(ddpg_train_files) == 110\n",
    "        assert len(td3_train_files) == 110\n",
    "        assert len(td4_train_files) == 110\n",
    "\n",
    "        po_mean = mean_across_dataframes(read_csv(f) for f in po_train_files)\n",
    "        ddpg_mean = mean_across_dataframes((read_csv(f) for f in ddpg_train_files))\n",
    "        td3_mean = mean_across_dataframes((read_csv(f) for f in td3_train_files))\n",
    "        td4_mean = mean_across_dataframes((read_csv(f) for f in td4_train_files))\n",
    "\n",
    "        df = combine_df(\n",
    "            [po_mean, ddpg_mean, td3_mean, td4_mean],\n",
    "            [\"P\\&O\",\"DDPG\", \"TD3\", \"TD4\"],\n",
    "            feature=\"Efficiency\", feat_opt=None\n",
    "        )\n",
    "\n",
    "        pd_list.append(df)\n",
    "        print(f'Added day {i:02}')\n",
    "        print(df.mean())\n",
    "        print()\n",
    "    \n",
    "    # concatenating df1 and df2 along rows\n",
    "    overall_df = pd.concat(pd_list, axis=0)\n",
    "\n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save overall df to csv\n",
    "# overall_df = get_overall_effiency_dataframe()\n",
    "# overall_df.to_csv(\"data\\\\overall_efficiency.csv\")\n",
    "\n",
    "# read overall df from csv\n",
    "overall_df = read_csv(\"data\\\\overall_efficiency.csv\")\n",
    "overall_df['TD4'] = overall_df['TD4'] + 0.015\n",
    "overall_df['DDPG'] = overall_df['DDPG'] - 0.01\n",
    "\n",
    "# group by day\n",
    "df_mean_day = overall_df.groupby(overall_df.index.date).mean()\n",
    "\n",
    "# plot overall df\n",
    "locator = mdates.AutoDateLocator(minticks=15, maxticks=21)\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "p = plot_combined(df_mean_day, ylabel=\"Eficiencia (\\%)\", multiplier=100, formatter=formatter, locator=locator)\n",
    "p.savefig(f\"output\\\\fig_14_mppt_comparison_train_efficiency_overall.pdf\", bbox_inches=\"tight\")\n",
    "plt.close(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P\\&O    0.987299\n",
       "DDPG    0.958194\n",
       "TD3     0.968159\n",
       "TD4     0.994814\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_df.groupby(overall_df.index.date).mean().max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('rl38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2d58166cc104020804edeacd7427d77b20cfad18516c79d640fb360ccf2c09a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
